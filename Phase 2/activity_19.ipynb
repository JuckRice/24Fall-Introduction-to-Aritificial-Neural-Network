{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "GArTXeOGl0EA"
      },
      "outputs": [],
      "source": [
        "# Goal: Implement a NN that adds two bits (a0 and b0) and outputs the sum (a0+b0 = c1c0)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the neural network model\n",
        "class AdderNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AdderNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(2, 3)  # Input: 2 bits, Output: 3 neurons\n",
        "    self.fc2 = nn.Linear(3, 2)  # Input: 3 neurons, Output: 2 bits (sum)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self, x): # [MOST IMPORTANT] the NN is defined here\n",
        "    h = self.relu(self.fc1(x)) # x is the input , h is the hidden activations\n",
        "    y = self.fc2(h) # h is the hidden activations, y is the final output\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OIyq0udUAE-L"
      },
      "outputs": [],
      "source": [
        "# prompt: create a binary addition dataset where x = [a, b], y = [d, c] where (dc)2 = (a)2 + (b)2\n",
        "\n",
        "def generate_binary_addition_dataset(num_samples):\n",
        "  \"\"\"Generates a dataset for binary addition.\"\"\"\n",
        "\n",
        "  x_data = []\n",
        "  y_data = []\n",
        "\n",
        "  for _ in range(num_samples):\n",
        "    a = torch.randint(0, 2, (1,)).item()\n",
        "    b = torch.randint(0, 2, (1,)).item()\n",
        "\n",
        "    # Calculate the sum in decimal\n",
        "    decimal_sum = a + b\n",
        "\n",
        "    # Convert the sum to binary (maximum 2 bits needed)\n",
        "    if decimal_sum == 0:\n",
        "      c = 0\n",
        "      d = 0\n",
        "    elif decimal_sum == 1:\n",
        "      c = 1\n",
        "      d = 0\n",
        "    elif decimal_sum == 2:\n",
        "      c = 0\n",
        "      d = 1\n",
        "\n",
        "    x_data.append([a, b])\n",
        "    y_data.append([d, c])\n",
        "\n",
        "  return torch.tensor(x_data, dtype=torch.float32), torch.tensor(y_data, dtype=torch.float32)\n",
        "\n",
        "# Generate the dataset\n",
        "x_train, y_train = generate_binary_addition_dataset(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1qrl9XJAhqI",
        "outputId": "63e917dc-b6d3-4f63-d0d0-3dda6de8ab6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 0.1303\n",
            "Epoch [200/1000], Loss: 0.1008\n",
            "Epoch [300/1000], Loss: 0.0863\n",
            "Epoch [400/1000], Loss: 0.0703\n",
            "Epoch [500/1000], Loss: 0.0565\n",
            "Epoch [600/1000], Loss: 0.0494\n",
            "Epoch [700/1000], Loss: 0.0457\n",
            "Epoch [800/1000], Loss: 0.0434\n",
            "Epoch [900/1000], Loss: 0.0420\n",
            "Epoch [1000/1000], Loss: 0.0410\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Create the model\n",
        "model = AdderNN()\n",
        "\n",
        "# Define the optimizer (SGD)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1) # GD, SGD, minibatch SGD, depending on how we measure the loss\n",
        "# SGD: w_next = w_now - lr * gradient\n",
        "# gradient = computed using backpropagation (aka dynamic programming for efficient gradient compute)\n",
        "\n",
        "# Define the loss function (mean squared error loss)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "num_iterations = 1000\n",
        "for iter in range(num_iterations):\n",
        "  # Forward pass\n",
        "  outputs = model(x_train)\n",
        "  # F(x), F is the neural net, x is the training input\n",
        "  loss = criterion(outputs, y_train)\n",
        "  # L(F(x), y), L is the loss, y is the training label\n",
        "\n",
        "  # Backward pass and optimization\n",
        "  optimizer.zero_grad() # [very important]\n",
        "  # for each parameter, they have two memory slots\n",
        "  # w, dL/dw\n",
        "  # dL/dW is not reset unless you say so\n",
        "  # optimizer.zero_grad() => it cleans up the gradient slots of\n",
        "  # all the variables specified in the optimizer\n",
        "  # After this, it becomes dL/dw = 0 for all w's in the given list\n",
        "  loss.backward() # one line magic call to run the backpropagation step\n",
        "  # After this, dL/dw = populated by backprop\n",
        "  optimizer.step()\n",
        "  # Excutes one step of SGD: w_next = w_now - lr * gradient\n",
        "  # After this, w is updated as shown above\n",
        "  # dL/dW stays there\n",
        "\n",
        "  if (iter + 1) % 100 == 0:\n",
        "    print(f'Epoch [{iter+1}/{num_iterations}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "  outputs = model(x_train)\n",
        "  predicted = (outputs > 0.5).float()\n",
        "  accuracy = (predicted == y_train).all(dim=1).float().mean()\n",
        "  print(f'Accuracy: {accuracy.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfoiMX6buKm3",
        "outputId": "813c250c-dbb5-47af-a489-1ba9032ce55b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.2950,  0.3536],\n",
              "        [-0.1639,  0.7644],\n",
              "        [ 0.0182,  1.0013],\n",
              "        [ 0.8698, -0.1142]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.Tensor([[0,0], [0,1], [1, 0], [1,1]]) # batch size =1 , the only input is [1,0]\n",
        "model(x) # all correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfVcbmCHBNub",
        "outputId": "446ef9b8-3348-487a-8541-90b993d3e3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 1.3319, -1.1752],\n",
            "        [ 1.1975, -0.4550],\n",
            "        [ 0.1733, -0.6872]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0006,  0.4568, -0.1736], requires_grad=True), Parameter containing:\n",
            "tensor([[-1.1151,  1.0085,  0.1972],\n",
            "        [ 1.2988, -0.9030, -0.2400]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1657,  0.7661], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "# prompt: convert model.parameters()  to list\n",
        "\n",
        "parameter_list = list(model.parameters())\n",
        "print(parameter_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yKp4tDLTyakt"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (936715431.py, line 4)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[66], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    f = f1_{w1} ( f2_{w2} (f3_{w3} (x)))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Consider fi_{wi}(x) = wi * x\n",
        "# Then, dfi/dwi = x, and dfi/dx = wi\n",
        "\n",
        "f = f1_{w1} ( f2_{w2} (f3_{w3} (x)))\n",
        "l = (f(x) - y)^2\n",
        "l = (f1(f2(f3(x))) - y)^2\n",
        "dl/df1 = 2(f1 - y)\n",
        "\n",
        "[dl / dw1, dl / dw2, dl / dw3]\n",
        "\n",
        "dl/dw1 = dl/df1 * df1/dw1                       = 2(f1 - y) * f2\n",
        "dl/dw2 = dl/df1 * df1/df2 * df2/dw2             = 2(f1 - y) * w1 * f3\n",
        "dl/dw3 = dl/df1 * df1/df2 * df2/df3 * df3/dw3   = 2(f1 - y) * w1 * w2 * x"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
